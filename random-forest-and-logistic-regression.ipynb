{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Description of Dataset\n\nThe provided data has the financial transaction data as well as the target variable **isFraud**, which is the actual fraud status of the transaction and **isFlaggedFraud** is the indicator which the simulation is used to flag the transaction using some threshold.\n\n## Issues with the Dataset\nThe main technical challenge it poses to predicting fraud is the highly imbalanced distribution between positive and negative classes in 6 million rows of data. "},{"metadata":{},"cell_type":"markdown","source":"# References\n* https://www.kaggle.com/netzone/eda-and-fraud-detection\n* https://www.kaggle.com/arjunjoshua/predicting-fraud-in-financial-payment-services"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, plot_confusion_matrix\n\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom scipy.stats import skew, boxcox\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/paysim1/PS_20174392719_1491204439457_log.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correct spelling of original column headers for consistency"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check for Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().values.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n The types of fraudulent transactions are {}'.format(\\\nlist(df.loc[df.isFraud == 1].type.drop_duplicates().values))) # only 'CASH_OUT' \n                                                             # & 'TRANSFER'\n\ndfFraudTransfer = df.loc[(df.isFraud == 1) & (df.type == 'TRANSFER')]\ndfFraudCashout = df.loc[(df.isFraud == 1) & (df.type == 'CASH_OUT')]\n\nprint ('\\n The number of fraudulent TRANSFERs = {}'.\\\n       format(len(dfFraudTransfer))) # 4097\n\nprint ('\\n The number of fraudulent CASH_OUTs = {}'.\\\n       format(len(dfFraudCashout))) # 4116","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(5, 3))\ndf.type.value_counts().plot(kind='bar', title=\"Transaction type\", ax=ax, figsize=(8,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.boxplot(x = 'isFraud', y = 'amount', data = df[df.amount < 1e5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 2, figsize=(10, 10))\ntmp = df.loc[(df.type == 'TRANSFER'), :]\n\na = sns.boxplot(x = 'isFlaggedFraud', y = 'amount', data = tmp, ax=axs[0][0])\naxs[0][0].set_yscale('log')\nb = sns.boxplot(x = 'isFlaggedFraud', y = 'oldBalanceDest', data = tmp, ax=axs[0][1])\naxs[0][1].set(ylim=(0, 0.5e8))\nc = sns.boxplot(x = 'isFlaggedFraud', y = 'oldBalanceOrig', data=tmp, ax=axs[1][0])\naxs[1][0].set(ylim=(0, 3e7))\nd = sns.regplot(x = 'oldBalanceOrig', y = 'amount', data=tmp.loc[(tmp.isFlaggedFraud ==1), :], ax=axs[1][1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df.groupby(['type', 'isFraud']).size().plot(kind='bar')\nax.set_title(\"# of transaction which are the actual fraud per transaction type\")\nax.set_xlabel(\"(Type, isFraud)\")\nax.set_ylabel(\"Count of transaction\")\nfor p in ax.patches:\n    ax.annotate(str(format(int(p.get_height()), ',d')), (p.get_x(), p.get_height()*1.01))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df.groupby(['type', 'isFlaggedFraud']).size().plot(kind='bar')\nax.set_title(\"# of transaction which is flagged as fraud per transaction type\")\nax.set_xlabel(\"(Type, isFlaggedFraud)\")\nax.set_ylabel(\"Count of transaction\")\nfor p in ax.patches:\n    ax.annotate(str(format(int(p.get_height()), ',d')), (p.get_x(), p.get_height()*1.01))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Feature Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_set = df[['step','amount','oldBalanceOrig','newBalanceOrig','oldBalanceDest','newBalanceDest','isFlaggedFraud']]\ny = df['isFraud']\nX = feature_set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Modelling**"},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier() #using default values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #use this random state to match my results only\n#training our model\nmodel = rfc.fit(X_train,y_train)\n#predicting our labels\npredictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predictions))\ncnf_matrix = confusion_matrix(y_test, predictions)\nplot_confusion_matrix(rfc, X_train,y_train)\n\naccuracy_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Random Forest Accuracy\", accuracy_score(y_test,predictions))\nprint(\"Recall metric in the testing dataset: {0:.4f}\".format(cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regreession"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = df.loc[(df.type=='TRANSFER')|(df.type=='CASH_OUT')]\ntmp.drop(['step', 'nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1, inplace=True)\ntmp = tmp.reset_index(drop=True)\ntmp['type_num'] = tmp.type.replace({'TRANSFER':1,'CASH_OUT':0})\ntmp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp.drop(['oldBalanceOrig', 'newBalanceOrig', 'oldBalanceDest', 'newBalanceDest', 'amount', 'type'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = tmp['isFraud']\nX = tmp.drop(['isFraud'], axis=1)\n\n# Number of data points in the minority class\nnumber_records_fraud = len(tmp[tmp.isFraud == 1])\nfraud_indices = tmp[tmp.isFraud == 1].index.values\n\n# Picking the indices of the normal classes\nnormal_indices = tmp[tmp.isFraud == 0].index\n\n# Out of the indices we picked, randomly select \"x\" number (x - same as total fraud)\nrandom_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\n# Appending the 2 indices\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\nunder_sample_data = tmp.iloc[under_sample_indices, :]\nunder_sample_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"under_sample_data = under_sample_data.sample(frac=1).reset_index(drop=True)\ny_undersample = under_sample_data['isFraud']\nX_undersample = under_sample_data.drop(['isFraud'],axis=1)\ny_undersample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Undersampled dataset\nX_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n                                                                                                   ,y_undersample\n                                                                                                   ,test_size = 0.3\n                                                                                                   ,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def printing_Kfold_scores(x_train_data, y_train_data, kfoldnum, c_array):\n    # define K-Fold\n    fold = KFold(kfoldnum,shuffle=False) \n    results_table = pd.DataFrame(columns = ['C_parameter','Mean recall score', 'Mean precision score'])\n    results_table['C_parameter'] = c_array\n    \n\n    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n    j = 0\n    for c_param in c_array:\n        print('-------------------------------------------')\n        print('C parameter: ', c_param)\n        print('-------------------------------------------')\n        print('')\n\n        recall_accs = []\n        precision_accs = []\n        for train_indices, test_indices in fold.split(x_train_data):\n        \n            # Call the logistic regression model with a certain C parameter\n            lr = LogisticRegression(C = c_param, penalty = 'l1', solver='liblinear')\n            \n\n            # Use the training data to fit the model. In this case, we use the portion of the fold to train the model\n            # with indices[0]. We then predict on the portion assigned as the 'test cross validation' with indices[1]\n            lr.fit(x_train_data.iloc[train_indices],y_train_data.iloc[train_indices])\n\n            # Predict values using the test indices in the training data\n            y_pred_undersample = lr.predict(x_train_data.iloc[test_indices])\n\n            # Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n            recall_acc = recall_score(y_train_data.iloc[test_indices],y_pred_undersample)\n            recall_accs.append(recall_acc)\n            \n            precision_acc = precision_score(y_train_data.iloc[test_indices], y_pred_undersample)\n            precision_accs.append(precision_acc)\n            print(\"recall score = {:.4f}, precision score = {:.4f}\".format(recall_acc, precision_acc))\n\n        # The mean value of those recall scores is the metric we want to save and get hold of.\n        results_table.loc[j,'Mean recall score'] = np.mean(recall_accs)\n        results_table.loc[j, 'Mean precision score'] = np.mean(precision_accs)\n        j += 1\n        print('')\n        print('Mean recall score {:.4f}'.format(np.mean(recall_accs)))\n        print('Mean precision score {:.4f}'.format(np.mean(precision_accs)))\n        print('')\n\n    best_c = results_table.iloc[results_table['Mean recall score'].astype(float).idxmax()]['C_parameter']\n    \n    # Finally, we can check which C parameter is the best amongst the chosen.\n    print('*********************************************************************************')\n    print('Best model to choose from cross validation is with C parameter = ', best_c)\n    print('*********************************************************************************')\n    \n    return best_c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_param_range = [0.001, 0.01, 0.1, 1, 10, 100]\nk_fold = 5\nbest_c = printing_Kfold_scores(X_train_undersample,y_train_undersample, k_fold, c_param_range)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C = best_c, penalty = 'l1', solver='liblinear')\nlr.fit(X_train_undersample,y_train_undersample.values.ravel())\ny_pred_undersample = lr.predict(X_test_undersample.values)\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\n\nprint (\"Logistic Regression Accuracy\", accuracy_score(y_test_undersample,y_pred_undersample))\nprint(\"Recall metric in the testing dataset: {0:.4f}\".format(cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])))\n\n# Plot non-normalized confusion matrix\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(lr, X_train_undersample,y_train_undersample.values.ravel(), labels=class_names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test_undersample,y_pred_undersample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}